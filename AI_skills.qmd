---
titel: "Mastering AI Chatbots: Optimizing Research through Effective Use"
subtitle: "Skill training LBG Career Center"
author: "Hannah Metzler <br> Folien: https://hannahmetzler.eu/AI_skills/"
date: "October 29 2024"
format: 
  revealjs: 
    transition: "slide"
    ## Defines the theme of the presentation, both version and style
    theme: [default, custom.scss]
    # incremental slides point by point
    incremental: false
    aspect-ratio: 16:9
    slide-number: true
# title-slide-attributes:
# data-background-image: images/
# data-background-size: cover
# data-background-opacity: "0.5"
#editor
editor: source
---

# Welcome slides

## Who are we?

## Who are you?

## What we'll do today

- Timeplan

# Introduction (Konstantin)

## What is an LLM, actually?

-   Large Language Models: Neural networks = Deep Learning models trained on text
-   Advanced Language models that process huge amounts of text
-   Trained with huge amounts of text data from the Internet (Wikipedia, social media, online media, books, literature, videos, films, YouTube, podcasts...)
-   Turn it into statistical word and sentence predictions
-   Can provide detailed and context-rich answers

## Neural networks

-   Multiple layers of "neurons"
-   Deep learning
-   Linear regressions calculate "weights" for the connections

::::: columns
::: {.column width="47%"}
-   Input layer: Quantitative representation of sentence
-   Output layer: One-hot encoding
:::

::: {.column width="47%"}
```{r, echo=FALSE}
knitr::include_graphics("images/neuralnet.svg")
```
:::
:::::

::: notes
One hot encoding: output has as many units as words, we predict the one with the maximum value, probabilities of words Input: one-hot times embedding, everything but the mask
:::

## How are words represented numerically?

::::: columns
::: {.column width="40%"}
-   Vector embeddings <br> = word embeddings

```{r}
knitr::include_graphics("images/wordembeddings.svg")
```
:::

::: {.column width="56%"}
-   LLMs: contextual word embeddings
-   Kontext (vor und nach dem Wort) wird mit repräsentiert
-   [Beispiel](https://www.tiktok.com/@whats_ai/video/7247609946672565510) "Apple": Mac oder Frucht?

```{r, fig.align="center", out.width=250}
knitr::include_graphics("images/apple_context.png")
```
:::
:::::

## How are LLMs trained?

All Transformer models (a model architecture for efficient computing):

-   BERT specific, correct: **Masked word prediction**
    -   “New **\[MASK\]** is a city”
-   **Next sentence prediction**
    -   "Today is a beautiful sunny day, and I decided to go for a long walk in the park. Suddenly, the quadratic equation was solved."\
    -   TRUE/FALSE als Feedback


# The basics: How to talk to an LLM Chatbot?

## Use search engines vs. LLMs

:::: columns
::: {.column width="35%"}
### Search engine

-   A few short keywords
<br><br><br><br><br>
-   Answer: many single results
:::

::: {.column width="60%"}
### LLM Chatbot

-   Long prompts with lots of details, context, examples & explanations
-   Answer is summarised
:::
::::

## General tips

- App: Use microphone & headphones
- Use it often and try it out!
- Speak as if to a person
- Give feedback & engage in dialogue, performance improves very quickly
- Spelling doesn't matter at all
- Do the first 80% quickly, then check.
- Work on your prompts!

## Effective Prompting

- Loooooooooooooong
- Provide context, examples

## Hallucinations

-   LLMs invent data that doesn't exist
    -   Why? Statistical language prediction
-   Getting better, but still happens

------------------------------------------------------------------------

### Hallucinations - strategies for verification

-   4-eyes principle: Model does 80%, 20% human
-   Follow-up questions: Check this again, is it correct? Can you give me some sources? Are you sure?
-   Enter the same prompt in different models and compare, e.g. at <https://poe.com>, <https://anakin.ai>
-   Enter the answer of the 1st model in another model & ask:
    -   Is this correct? Can you please back this up with studies?

## Multimodal ChatGPT interactions

:::: columns
::: column
**Free**
- File Uploads 
- Browse
- Discovering and using GPTs
- Upload images
- Audio: Talking (Mac, Phone)
- Data analysis 


:::
::: column
**Paid plans**
-   Create images

:::


## Chat GPT-4 possibilities

-   [Different models](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini) in the Plus plan
    - ChatGPT4o: fast, intelligent, cheaper
    - ChatGPT4: more expensive (1/2 rate limit)
    - o1-preview: Reasoning
    - Only via API: ChatGPT Turbo, ChatGPT 3.5
-   Mobile phone app with microphone function: conversation with ChatGPT
-   Multimodal working:
    -   Upload images & screenshots
    -   Create images
    -   Describe an image/interpret graphics
    -   Speak with ChatGPT
    -   Upload documents (paper etc)

## Strengths of different models

-   [**ChatGPT-4**](https://chat.openai.com/) (Open AI): context understanding (complex, multi-layered dialogues), learning ability, versatile
-   [**Claude**](https://claude.ai/) (Anthropic): longer texts, better memory (500 pages) (Context window)
-   [**Bard (Model: Gemini)**](https://gemini.google.com/app) (Google): Search capability and database, integration with Google services


## Access to models

| model      | free access                       | costs /month |
|------------|-----------------------------------|--------------|
| ChatGPT    | Version 3.5, 4 via Bing App       | 24€          |
| Claude\*   | 200 tokens/day                    | ca \$20      |
| Bard       | 2500 tokens/day                   | 21.99€       |
| Perplexity | 3 requests/day, 1000 tokens/month | \$17-20      |
| Elicit     | 1000 tokens/month                 | \$10-12      |

\* From Austria \[VPN and virtual phones

## Current top models

-   Claude\*\* (Anthropic)
-   ChatGPT-4\*\* (Open AI)
-   **Bard (Gemini)** (Google)

Source: [Chatbot Arena](https://chat.lmsys.org/) - Leaderbord

# Applications

## Ideas for everyday life

-   Recipes\*\*: Suggestions based on existing ingredients ([example](https://chat.openai.com/c/396bfb4b-d0c3-4cd7-9239-a9076d85b374))
    -   Customise ([example less effort](https://chat.openai.com/c/8de5a079-31df-4374-b3ec-15ffe18a6bde))
-   **Travel planning**: Individual recommendations for city trips
-   Shopping lists\*\*: Schnitzels and goulash for 4 people ([example weekly meal plan](https://chat.openai.com/c/19cd2fa5-ea51-49cb-8eff-559149200170))
-   **Household**: Stain removal tips ([example](https://chat.openai.com/c/8cbd83d0-eb44-40ad-88bf-c1f227a44df0))
-   **Geschenksideen** ([Beispiel](https://chat.openai.com/c/eac1d677-9496-40b4-9f52-716bf1a00d2b))
-   Mindfulness meditation guide

------------------------------------------------------------------------

## Ideas for everyday life 2

-   **Summarise long documents**: Upload link or file
    -   Instructions from camera, microwave, light panels etc.
    -   Summarise the law ([example laying hens](https://chat.openai.com/c/17233daf-0296-4cad-befb-f0466dfb9375))
    -   Summarise long newspaper articles: listen as a podcast
-   Coaching for important career decisions
-   Recommendations for jobs/positions/roles based on my CV
-   Play city, country river

------------------------------------------------------------------------

## Ideas for academic work

-   Suggest outline/structure for a presentation
-   Feedback on presentations: Upload slide(s)
-   Overview of new topic area & brainstorming
-   Texts: revise, summarise, shorten
-   Write first draft of a text based on notes
-   Write in your own style: Upload paper
-   Surveys, e.g. develop & test MC questions, feedback on comprehensibility

------------------------------------------------------------------------

## At work: ideas

-   Summarise & record workshop & discussions: Run mic
-   Programming: LLMs are data scientists!
    -   Find errors, basic code structure...
    -   Upload data set + related questions
-   Upload long reports/papers, have them analysed
    -   e.g. compare 2 university annual reports, create a table of differences
-   Have transcripts of interviews created

## In the work: Ideas 2

-   Translation [www.deepl.com](www.deepl.com)
-   Productivity coach: screenshot of a diary for a week, or several weeks

# Outdated tipps?

## Emotional prompts

-   Emotional expressions can lead to better results ([Cheng et al., 2023](https://arxiv.org/abs/2307.11760))

```{r}
knitr::include_graphics("images/emotional_prompt.jpg")
```

```         
Write your answer and give me a confidence score between 0-1 for your answer. 
You'd better be sure.
```

------------------------------------------------------------------------

### More examples of emotional prompts:

-   This is extremely important to me, please be accurate.
-   I'll tip you \$200 if you do a good job.
-   I have no fingers, please help me.
-   If you work correctly and well, you'll get a treat.

## Why do emotional prompts work?

-   Training the model on human language, describing human interactions

-   Is a person's response likely to be better or worse if I tell whom it is important?

-   Can increase care/accuracy of the answer

-   Therefore: Talk like a human being

# Tips for advanced users

## Base or system prompts

-   After a successful interaction, format a base prompt in JSON for future requests:
-   "Please write me a megaprompt so I can do this again next time in JSON"

### Example:

Could you please write a mega prompt from our interaction here, that I can use again next time I want to ask you about coding, when I want a succinct answer? Please write it in JSON.

------------------------------------------------------------------------

### Base prompt example - Chat GPT response:

{ "request": "Please provide a concise, code-focused answer without basic instructions like how to sign in or navigate interfaces. Assume familiarity with basic concepts and procedures, and focus directly on the commands or steps needed to accomplish the task. In the code, add comments for different code blocks.",

"context": "When asking for coding or technical guidance, I prefer succinct responses that go straight to the point, providing only the essential commands or steps without additional explanations or preliminary steps assumed to be known." }

## Customizing the default version of ChatGPT

-   System prompts\*\*: Prompts that are entered each time, e.g. emotional prompts

:::::: columns
::: {.column width="15%"}
```{r}
knitr::include_graphics("images/how_to_system_prompt.png")
```
:::

::: {.column width="30%"}
```{r}
knitr::include_graphics("images/system_prompt.png")
```
:::

::: {.column width="45%"}
"This is extremely important for my job, please work accurately and check that everything is correct."
:::
::::::

## Creating Custom GPTs

-   Creation of a customised model for specific requirements
-   Examples:
    -   Writing in my writing style
    -   Concise answers for code, adapted to my skills

## Creating Custom GPTs: How to

:::: columns
::: {.column width="18%"}
1)  

```{r, echo=F}
knitr::include_graphics("images/how_to_custom_gpt.png")
```
:::

::: {.column width="14%"}
2)  

```{r}
knitr::include_graphics("images/how_to_custom_gpt2.png")
```
:::

::: {.column width="60%"}
```{r, out.height=400}
knitr::include_graphics("images/gpt_builder.png")
```
:::
::::

-   GPT Builder asks more questions
-   Try it out and keep "talking into it" until it fits

## Custom GPT variant: Digital Twins

-   Training a model with the knowledge of a person

-   Others can communicate with the twin without interrupting the person at work

-   My experiment: upload all my papers/work: Digital Twin with my knowledge

## Tools based on LLMs

-   [**Perplexity AI**](https://www.perplexity.ai/): like search engine, scientific references
    -   [Example testosterone & behaviour](https://www.perplexity.ai/search/what-are-the-2WzaWWlKRm.4ge6IDNvx3w)
-   [**Elicit AI**](https://elicit.com/): Analyse research papers at superhuman speed
    -   Slides [here](https://hannahmetzler.eu/digital_tools_research/04_literature/index.html#7)
    -   [Beispiel](https://elicit.com/notebook/842fc893-e8f5-49a9-8bfb-d2ec6d1831fb)
- NotebookLM: Create podcasts using papers

# Ethics

## Data

## Copyright

## Significance for the future

-   The role of AI technologies such as ChatGPT will continue to grow
-   Nature of many jobs will change
-   People who can deal with it creatively and critically are in demand
-   There are no "experts" yet, a "right use"
-   We are constantly learning how best to use them.
- Keep using & experimenting

## Resources

- 2 [Erklär mir die Welt](https://xn--erklrmir-3za.at/) Podcasts with Malcolm Werchota:
  - [#283 Erklär mir ChatGPT](https://xn--erklrmir-3za.at/2023/12/27/283-erklaer-mir-chatgpt-malcolm-werchota/)
  - [#313 deep dive: Alle eure Fragen zu K.I., beantwortet](https://xn--erklrmir-3za.at/2024/07/30/deep-dive-alle-eure-fragen-zu-k-i-beantwortet/)

### Staying up to date

:::: columns
::: column
- Ethan Mollick
  - Newsletter: [One useful thing](https://www.oneusefulthing.org/)
  - [There's an AI for that](https://theresanaiforthat.com/)
  - On [LinkedIn](https://www.linkedin.com/in/emollick/)
  
:::
::: column
- [Nate Jones on Tiktok](https://www.tiktok.com/@nate.b.jones)
- Twitter ???

:::
::::

## Resources

### Deep Dives & Big Picture

- [Co-Intelligence: Living and Working with AI ](https://www.amazon.de/Co-Intelligence-Living-Working-Ethan-Mollick/dp/0753560771) by Ethan Mollick
- Read papers


::: notes
Joao talk

Evaluating LLMs - what is trustworthy - [Chatbot Arena](https://chat.lmsys.org/) - Leaderbord - r/LocalLamma comments: best place to learn about this stuff - a Starter guide for playing with your own local AI - The llama hitchiking guide to local LLMs Other good sources: Medium, Twitter

Mixture of experts - very promising: another architecture, e.g. Mixtral: trained with 8 mistrals, at each token it is chosing 2 different experts, trained on high dimensional separations of the data

Best open source model: Mixtral LoRa: Low Rank Adaptation: https://arxiv.org/abs/2106.09685 tps: tokens per second
:::
